{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX 1080 (CNMeM is disabled, cuDNN 5110)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.sandbox.cuda.dnn import dnn_conv\n",
    "from theano.tensor.nnet import conv2d, relu\n",
    "from six.moves import cPickle\n",
    "#data from http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import glob\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import scipy.signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "image_list = map(lambda x: x.resize((64,64)),\n",
    "                 map(Image.open, glob(\"../data/img_align_celeba/img_align_celeba/*.jpg\")))\n",
    "image_array = np.array(list(map(np.asarray, image_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b68d1436a5c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_array\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "plt.imshow(image_array[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def rescale(x, old=[0,255], new=[-1,1], invert = False):\n",
    "    if invert:\n",
    "        temp = old\n",
    "        old = new\n",
    "        new = temp\n",
    "        \n",
    "    return (x - old[0])/(old[1] - old[0]) * (new[1] -new[0]) + new[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def deconv(X, w, subsample=(1, 1), border_mode=(0, 0), conv_mode='conv'):\n",
    "    #https://github.com/Newmu/dcgan_code/lib/ops.py\n",
    "    from theano.sandbox.cuda.basic_ops import (gpu_contiguous, gpu_alloc_empty)\n",
    "    from theano.sandbox.cuda.dnn import GpuDnnConvDesc, GpuDnnConvGradI\n",
    "    \"\"\" \n",
    "    sets up dummy convolutional forward pass and uses its grad as deconv\n",
    "    currently only tested/working with same padding\n",
    "    \"\"\"\n",
    "    img = gpu_contiguous(X)\n",
    "    kerns = gpu_contiguous(w)\n",
    "    desc = GpuDnnConvDesc(border_mode=border_mode, subsample=subsample,\n",
    "                          conv_mode=conv_mode)(gpu_alloc_empty(img.shape[0], kerns.shape[1], img.shape[2]*subsample[0], img.shape[3]*subsample[1]).shape, kerns.shape)\n",
    "    out = gpu_alloc_empty(img.shape[0], kerns.shape[1], img.shape[2]*subsample[0], img.shape[3]*subsample[1])\n",
    "    d_img = GpuDnnConvGradI()(kerns, img, out, desc)\n",
    "    return d_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def lrelu(x, leak=0.2):\n",
    "    #https://github.com/bamos/dcgan-completion.tensorflow/blob/master/ops.py\n",
    "    return(T.nnet.relu(x, alpha=leak))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def batchnorm(X, g=None, b=None, u=None, s=None, a=1., e=1e-8):\n",
    "    \"\"\"\n",
    "    batchnorm with support for not using scale and shift parameters\n",
    "    as well as inference values (u and s) and partial batchnorm (via a)\n",
    "    will detect and use convolutional or fully connected version\n",
    "    \"\"\"\n",
    "    if X.ndim == 4:\n",
    "        if u is not None and s is not None:\n",
    "            b_u = u.dimshuffle('x', 0, 'x', 'x')\n",
    "            b_s = s.dimshuffle('x', 0, 'x', 'x')\n",
    "        else:\n",
    "            b_u = T.mean(X, axis=[0, 2, 3]).dimshuffle('x', 0, 'x', 'x')\n",
    "            b_s = T.mean(T.sqr(X - b_u), axis=[0, 2, 3]).dimshuffle('x', 0, 'x', 'x')\n",
    "        if a != 1:\n",
    "            b_u = (1. - a)*0. + a*b_u\n",
    "            b_s = (1. - a)*1. + a*b_s\n",
    "        X = (X - b_u) / T.sqrt(b_s + e)\n",
    "        if g is not None and b is not None:\n",
    "            X = X*g.dimshuffle('x', 0, 'x', 'x') + b.dimshuffle('x', 0, 'x', 'x')\n",
    "    elif X.ndim == 2:\n",
    "        if u is None and s is None:\n",
    "            u = T.mean(X, axis=0)\n",
    "            s = T.mean(T.sqr(X - u), axis=0)\n",
    "        if a != 1:\n",
    "            u = (1. - a)*0. + a*u\n",
    "            s = (1. - a)*1. + a*s\n",
    "        X = (X - u) / T.sqrt(s + e)\n",
    "        if g is not None and b is not None:\n",
    "            X = X*g + b\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class ConvLayer(object):\n",
    "    #https://github.com/mikesj-public/dcgan-autoencoder\n",
    "    #Output must be an integer multiple of input, please use powers of 2\n",
    "    def __init__(self, input,\n",
    "                 input_size, output_size, \n",
    "                 num_input_filters, num_output_filters, \n",
    "                 W = None, filter_size = 5, \n",
    "                 activation = None,\n",
    "                 rng = np.random.RandomState()):\n",
    "        self.input = input\n",
    "        \n",
    "        is_deconv = output_size >= input_size\n",
    "\n",
    "        #Size of 4d convolution tensor\n",
    "        w_size = np.array([num_input_filters, num_output_filters, filter_size, filter_size]) \\\n",
    "                if is_deconv \\\n",
    "                else np.array([num_output_filters, num_input_filters, filter_size, filter_size])\n",
    "        #Initialize weights\n",
    "        if W == None:\n",
    "            W_values = np.asarray(\n",
    "                rng.normal(\n",
    "                    scale = .02,\n",
    "                    size = (w_size)\n",
    "                ),\n",
    "                dtype=theano.config.floatX\n",
    "            )\n",
    "            W = theano.shared(value=W_values, name='W', borrow=True)\n",
    "        self.W = W\n",
    "        \n",
    "        conv_method = deconv if is_deconv else conv2d\n",
    "\n",
    "        #Size of subsampling\n",
    "        sub = output_size / input_size \\\n",
    "            if is_deconv else input_size / output_size\n",
    "        sub = int(sub)\n",
    "        #Border size\n",
    "        if filter_size == 3:\n",
    "            bm = 1\n",
    "        else:\n",
    "            bm = 2\n",
    "            \n",
    "        #Output\n",
    "        lin_output = conv_method(input, W, subsample=(sub, sub), border_mode=(bm, bm))\n",
    "        if activation is not None:\n",
    "            output = activation(lin_output)\n",
    "        else: output = lin_output\n",
    "        self.output = output\n",
    "        \n",
    "        #Model parameters\n",
    "        self.params = [self.W] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class FullyConnected(object):\n",
    "    #http://deeplearning.net/tutorial/mlp.html\n",
    "    def __init__(self, input, n_in, n_out, W = None, b = None,\n",
    "                 activation = None, rng = np.random.RandomState()):\n",
    "        \n",
    "        self.input = input\n",
    "        \n",
    "        if W is None:\n",
    "            W_values = np.asarray(\n",
    "                rng.normal(\n",
    "                    scale = .02,\n",
    "                    size=(n_in, n_out)\n",
    "                ),\n",
    "                dtype=theano.config.floatX\n",
    "            )\n",
    "            W = theano.shared(value=W_values, name='W', borrow=True)\n",
    "        else: self.W = W\n",
    "\n",
    "        if b is None:\n",
    "            b_values = np.zeros((n_out,), dtype=theano.config.floatX)\n",
    "            b = theano.shared(value=b_values, name='b', borrow=True)\n",
    "        else: self.b = b\n",
    "\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        \n",
    "        # parameters of the model\n",
    "        self.params = [self.W, self.b]\n",
    "        \n",
    "        lin_output = T.dot(input, self.W) + self.b\n",
    "        self.output = (\n",
    "            lin_output if activation is None\n",
    "            else activation(lin_output)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Generator(object):\n",
    "    #https://arxiv.org/pdf/1511.06434.pdf\n",
    "    def __init__(self, input, params = None, \n",
    "                 rng = np.random.RandomState(),\n",
    "                 zsize = 100):\n",
    "        self.input = input\n",
    "        \n",
    "        h_input = input\n",
    "        \n",
    "        h = FullyConnected(\n",
    "            input=h_input,\n",
    "            n_in=zsize,\n",
    "            n_out=4*4*1024,\n",
    "            W = params[0] if params is not None else None,\n",
    "            b = params[1] if params is not None else None,\n",
    "            rng=rng,\n",
    "        )\n",
    "        h_out = relu(batchnorm(h.output.reshape((input.shape[0],1024,4,4))))\n",
    "        \n",
    "        conv1 = ConvLayer(h_out, 4, 8, 1024, 512,\n",
    "                          rng = rng,\n",
    "                          W = params[2] if params is not None else None\n",
    "                         ) \n",
    "        conv1_out = relu(batchnorm(conv1.output))\n",
    "        \n",
    "        conv2 = ConvLayer(conv1_out, 8, 16, 512, 256,\n",
    "                          rng = rng,\n",
    "                          W = params[3] if params is not None else None\n",
    "                         ) \n",
    "        conv2_out = relu(batchnorm(conv2.output))\n",
    "        \n",
    "        conv3 = ConvLayer(conv2_out, 16, 32, 256, 128,\n",
    "                          rng = rng,\n",
    "                          W = params[4] if params is not None else None\n",
    "                         ) \n",
    "        conv3_out = relu(batchnorm(conv3.output))\n",
    "        \n",
    "        conv4 = ConvLayer(conv3_out, 32, 64, 128, 3,\n",
    "                          rng = rng,\n",
    "                          W = params[5] if params is not None else None\n",
    "                         ) \n",
    "        conv4_out = T.tanh(conv4.output)\n",
    "        \n",
    "        self.output = conv4_out\n",
    "        self.params = h.params + conv1.params + conv2.params + \\\n",
    "                conv3.params + conv4.params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Critic(object):\n",
    "    #https://arxiv.org/pdf/1511.06434.pdf\n",
    "    def __init__(self, input, params = None, \n",
    "                 rng = np.random.RandomState()):\n",
    "        self.input = input\n",
    "        \n",
    "        conv1 = ConvLayer(input,64,32,3,64,\n",
    "                          rng = rng,\n",
    "                          W = params[0] if params is not None else None\n",
    "                         ) \n",
    "        conv1_out = lrelu(conv1.output)\n",
    "        \n",
    "        conv2 = ConvLayer(conv1_out, 32, 16, 64, 128,\n",
    "                          rng = rng,\n",
    "                          W = params[1] if params is not None else None\n",
    "                         ) \n",
    "        conv2_out = lrelu(batchnorm(conv2.output))\n",
    "        \n",
    "        conv3 = ConvLayer(conv2_out, 16, 8, 128, 256,\n",
    "                          rng = rng,\n",
    "                          W = params[2] if params is not None else None\n",
    "                         ) \n",
    "        conv3_out = lrelu(batchnorm(conv3.output))\n",
    "        \n",
    "        conv4 = ConvLayer(conv3_out, 8, 4, 256, 512,\n",
    "                          rng = rng,\n",
    "                          W = params[3] if params is not None else None\n",
    "                         ) \n",
    "        conv4_out = lrelu(batchnorm(conv4.output))\n",
    "        \n",
    "        h_input = conv4_out.flatten(2)\n",
    "        h = FullyConnected(\n",
    "            input=h_input,\n",
    "            n_in=512*4*4,\n",
    "            n_out=1,\n",
    "            W = params[4] if params is not None else None,\n",
    "            b = params[5] if params is not None else None,\n",
    "            rng=rng\n",
    "        )\n",
    "        h_out = T.nnet.sigmoid(h.output)\n",
    "        \n",
    "        self.output = h.output\n",
    "        self.params = conv1.params + conv2.params + \\\n",
    "                conv3.params + conv4.params + h.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def Adam(cost, params, lr=0.0002, b1=0.9, b2=0.999, e=1e-8, c=None):\n",
    "    #https://gist.github.com/Newmu/acb738767acb4788bac3\n",
    "    #Standard literature says b1=.9\n",
    "    #DCGAN paper says b1 = .5\n",
    "    b1 = 1-b1\n",
    "    b2 = 1-b2\n",
    "    updates = []\n",
    "    grads = T.grad(cost, params)\n",
    "    i = theano.shared(np.float32(0.))\n",
    "    i_t = i + 1.\n",
    "    fix1 = 1. - (1. - b1)**i_t\n",
    "    fix2 = 1. - (1. - b2)**i_t\n",
    "    lr_t = lr * (T.sqrt(fix2) / fix1)\n",
    "    for p, g in zip(params, grads):\n",
    "        m = theano.shared(p.get_value() * 0.)\n",
    "        v = theano.shared(p.get_value() * 0.)\n",
    "        m_t = (b1 * g) + ((1. - b1) * m)\n",
    "        v_t = (b2 * T.sqr(g)) + ((1. - b2) * v)\n",
    "        g_t = m_t / (T.sqrt(v_t) + e)\n",
    "        p_t = p - (lr_t * g_t) if c is None else T.clip(p - (lr_t * g_t), -c, c)\n",
    "        updates.append((m, m_t))\n",
    "        updates.append((v, v_t))\n",
    "        updates.append((p, p_t))\n",
    "    updates.append((i, i_t))\n",
    "    return updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def RMSprop(cost, params, lr=0.00005, rho=0.99, epsilon=1e-8, c=None):\n",
    "    #https://github.com/Newmu/Theano-Tutorials\n",
    "    #rho = .99 is torch default, used in WGAN paper\n",
    "    grads = T.grad(cost=cost, wrt=params)\n",
    "    updates = []\n",
    "    for p, g in zip(params, grads):\n",
    "        acc = theano.shared(p.get_value() * 0.)\n",
    "        acc_new = rho * acc + (1 - rho) * g ** 2\n",
    "        gradient_scaling = T.sqrt(acc_new + epsilon)\n",
    "        g = g / gradient_scaling\n",
    "        updates.append((acc, acc_new))\n",
    "        update = p - lr * g if c is None else T.clip(p - lr * g, -c, c)\n",
    "        updates.append((p, update))\n",
    "    return updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def gradDesc(cost, params, lr=.00005, c = None):\n",
    "    grads = T.grad(cost=cost, wrt=params)\n",
    "    updates = []\n",
    "    for p, g in zip(params, grads):\n",
    "        update = p - lr * g if c is None else T.clip(p - lr * g, -c, c)\n",
    "        updates.append((p, update))\n",
    "    return updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def log_progress(sequence, every=None, size=None, name='Items'):\n",
    "    #https://github.com/alexanderkuk/log-progress\n",
    "    from ipywidgets import IntProgress, HTML, VBox\n",
    "    from IPython.display import display\n",
    "\n",
    "    is_iterator = False\n",
    "    if size is None:\n",
    "        try:\n",
    "            size = len(sequence)\n",
    "        except TypeError:\n",
    "            is_iterator = True\n",
    "    if size is not None:\n",
    "        if every is None:\n",
    "            if size <= 200:\n",
    "                every = 1\n",
    "            else:\n",
    "                every = int(size / 200)     # every 0.5%\n",
    "    else:\n",
    "        assert every is not None, 'sequence is iterator, set every'\n",
    "\n",
    "    if is_iterator:\n",
    "        progress = IntProgress(min=0, max=1, value=1)\n",
    "        progress.bar_style = 'info'\n",
    "    else:\n",
    "        progress = IntProgress(min=0, max=size, value=0)\n",
    "    label = HTML()\n",
    "    box = VBox(children=[label, progress])\n",
    "    display(box)\n",
    "\n",
    "    index = 0\n",
    "    try:\n",
    "        for index, record in enumerate(sequence, 1):\n",
    "            if index == 1 or index % every == 0:\n",
    "                if is_iterator:\n",
    "                    label.value = '{name}: {index} / ?'.format(\n",
    "                        name=name,\n",
    "                        index=index\n",
    "                    )\n",
    "                else:\n",
    "                    progress.value = index\n",
    "                    label.value = u'{name}: {index} / {size}'.format(\n",
    "                        name=name,\n",
    "                        index=index,\n",
    "                        size=size\n",
    "                    )\n",
    "            yield record\n",
    "    except:\n",
    "        progress.bar_style = 'danger'\n",
    "        raise\n",
    "    else:\n",
    "        progress.bar_style = 'success'\n",
    "        progress.value = index\n",
    "        label.value = \"{name}: {index}\".format(\n",
    "            name=name,\n",
    "            index=str(index or '?')\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class DCGAN(object):\n",
    "    def __init__(self,\n",
    "                 genParams = None, critParams = None,\n",
    "                 zsize = 100,\n",
    "                 rng = np.random.RandomState(),\n",
    "                 critLosses = [],\n",
    "                 genLosses = []\n",
    "                ):\n",
    "        self.rng = rng\n",
    "        self.genParams = genParams\n",
    "        self.critParams = critParams\n",
    "        self.zsize = zsize\n",
    "        \n",
    "        self.critLosses = critLosses\n",
    "        self.genLosses = genLosses\n",
    "        \n",
    "    def train(self, X, iters = 600000,\n",
    "              alpha = .00005,\n",
    "              momentum = .9, m = 64, ncrit = 5,\n",
    "              optimizer = \"Adam\",\n",
    "              verbose = False, runningSave = False,\n",
    "              runningFile=\"Running Save/DCGAN\"):\n",
    "        \n",
    "        print(\"Building model...\")\n",
    "         # allocate symbolic variables for the data\n",
    "        z = T.matrix('z')  \n",
    "        x = T.tensor4('x')\n",
    "        \n",
    "        #Generator setup\n",
    "        gen = Generator(z, zsize=self.zsize, params=self.genParams, rng=self.rng)\n",
    "        self.gen = gen\n",
    "        self.genParams = gen.params\n",
    "        \n",
    "        #Critic setup\n",
    "        critTarget = Critic(x, params=self.critParams, rng=self.rng)\n",
    "        self.critTarget = critTarget\n",
    "        #critTrue params must be the same as critG params\n",
    "        critG = Critic(gen.output, params=critTarget.params, rng=self.rng)\n",
    "        self.critG = critG\n",
    "        self.critParams = critTarget.params\n",
    "        \n",
    "        print(\"Building optimizers...\")\n",
    "        genLoss = T.mean(T.log(1-self.critG.output))\n",
    "        critLoss = T.mean(T.log(self.critTarget.output)) \\\n",
    "                    + T.mean(T.log(1-self.critG.output))\n",
    "        if optimizer == \"Adam\":\n",
    "            genUpdates = Adam(genLoss, self.genParams, lr=alpha, b1=momentum)\n",
    "            critUpdates = Adam(-critLoss, self.critParams, lr=alpha, b1=momentum)\n",
    "        elif optimizer == \"RMSprop\":\n",
    "            genUpdates = RMSprop(genLoss, self.genParams, lr=alpha, rho=momentum)\n",
    "            critUpdates = RMSprop(-critLoss, self.critParams, lr=alpha, rho=momentum)\n",
    "        else:\n",
    "            genUpdates = gradDesc(genLoss, genParams, lr=alpha)\n",
    "            critUpdates = gradDesc(-critLoss, critParams, lr=alpha)\n",
    "            optimizer = \"Vanilla SGD\"\n",
    "        print(\"Using \" + optimizer)\n",
    "        \n",
    "        #Training functions\n",
    "        trainGen = theano.function(\n",
    "            inputs = [z],\n",
    "            outputs = genLoss,\n",
    "            updates = genUpdates\n",
    "        )\n",
    "        trainCrit = theano.function(\n",
    "            inputs = [z,x],\n",
    "            outputs = critLoss,\n",
    "            updates = critUpdates\n",
    "        )\n",
    "        print(\"Done!\")\n",
    "        \n",
    "        print(\"\\nBegin training...\")\n",
    "        def printIter(i):\n",
    "             print(\"Iteration %i/%i (%.2f%%)\" % \n",
    "                         (\n",
    "                            i+1,\n",
    "                            iters,\n",
    "                            100*(i+1)/iters,\n",
    "                         )\n",
    "                     )\n",
    "                \n",
    "        #Begin training\n",
    "        for i in log_progress(range(iters), every = 1, name = \"Iteration\"):\n",
    "            #Print stuff\n",
    "            if i == 0 or verbose or (i+1) % 500 == 0 or iters <= 500:\n",
    "                printIter(i)\n",
    "            if (i+1) % 500 == 0:\n",
    "                #Plot loss\n",
    "                self.plot()\n",
    "                #Show images\n",
    "                import itertools\n",
    "                k = 10\n",
    "                Z = np.random.uniform(-1,1,(k*k,100))\n",
    "                Z = Z.astype(\"float32\")\n",
    "                gX = self.sample(None, Z)\n",
    "                fig, axes = plt.subplots(k, k, figsize=(20,20))\n",
    "                for row, col in itertools.product(range(k), range(k)):\n",
    "                    gx = gX[row*k+col]\n",
    "                    axes[row,col].get_yaxis().set_visible(False)\n",
    "                    axes[row,col].get_xaxis().set_visible(False)\n",
    "                    axes[row,col].imshow(rescale((gx.transpose(1,2,0)), invert=True).astype('uint8'))\n",
    "                    fig.subplots_adjust(hspace=0, wspace=0)\n",
    "                plt.show()\n",
    "                #Save\n",
    "                if runningSave:\n",
    "                    self.save(runningFile + str(i+1))\n",
    "                    \n",
    "            #Update parameters\n",
    "            for n in range(ncrit):\n",
    "                #Generate critic samples:\n",
    "                Zm = self.rng.uniform(low = -1, high = 1, \n",
    "                  size=(m,self.zsize)).astype(theano.config.floatX)\n",
    "                Xm = X[self.rng.randint(X.shape[0], size=m)]\n",
    "                \n",
    "                #Update critic\n",
    "                critLoss = trainCrit(Zm, Xm)\n",
    "                \n",
    "            #Generate generator samples:\n",
    "            Zm = self.rng.uniform(low = -1, high = 1, \n",
    "              size=(m,self.zsize)).astype(theano.config.floatX)\n",
    "            \n",
    "            #Update generator\n",
    "            genLoss = trainGen(Zm)\n",
    "            self.genLosses.append(genLoss)\n",
    "            self.critLosses.append(critLoss)\n",
    "        self.plot()\n",
    "    \n",
    "    def sample(self, n=1, Z = None):\n",
    "        if Z is None:\n",
    "            Z = self.rng.uniform(low = -1, high = 1, \n",
    "                      size=(n,self.zsize)).astype(theano.config.floatX)\n",
    "        \n",
    "        gen = Generator(Z, zsize=self.zsize, params=self.genParams, rng=self.rng)\n",
    "        \n",
    "        return(gen.output.eval())\n",
    "    \n",
    "    def plot(self, kernel_size=101):\n",
    "        from matplotlib import pyplot as plt\n",
    "        %matplotlib inline\n",
    "        plt.figure()\n",
    "        plt.plot(self.critLosses)\n",
    "        plt.title(\"Critic loss \" + str(self.critLosses[-1]))\n",
    "        plt.xlabel(\"Generator iterations\")\n",
    "        plt.figure()\n",
    "        plt.plot(self.genLosses)\n",
    "        plt.title(\"Generator loss \" + str(self.genLosses[-1]))\n",
    "        plt.xlabel(\"Generator iterations\")\n",
    "        plt.show()\n",
    "    \n",
    "    def save(self, filename=\"DCGAN\"):\n",
    "        save_file = open(\"../models/\" + filename, 'wb')  # this will overwrite current contents\n",
    "        tosave = [self.genParams, self.critParams, self.rng, self.critLosses, self.genLosses]\n",
    "        for param in tosave:\n",
    "            # the -1 is for HIGHEST_PROTOCOL\n",
    "            cPickle.dump(param, save_file, -1)  \n",
    "        save_file.close()\n",
    "    \n",
    "    def from_file(filename=\"DCGAN\"):\n",
    "        f = open(\"../models/\" + filename, 'rb')\n",
    "        genParams = cPickle.load(f)\n",
    "        critParams = cPickle.load(f)\n",
    "        rng = cPickle.load(f)\n",
    "        critLosses = cPickle.load(f)\n",
    "        genLosses = cPickle.load(f)\n",
    "        clf = DCGAN(\n",
    "            genParams=genParams,\n",
    "            critParams=critParams,\n",
    "            rng = rng,\n",
    "            critLosses=critLosses,\n",
    "            genLosses=genLosses\n",
    "        )\n",
    "        return(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = image_array.transpose(0, 3, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Preprocess \n",
    "x = rescale(x).astype(theano.config.floatX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Initialize\n",
    "dcgan = DCGAN(rng = np.random.RandomState(1234),\n",
    "            zsize = 100\n",
    "           )\n",
    "#Train\n",
    "dcgan.train(x, iters = 100000, m = 128, ncrit = 1,\n",
    "           alpha = .0002, momentum = .5,\n",
    "           optimizer = \"Adam\"\n",
    "          )\n",
    "dcgan.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dcgan.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "k = 10\n",
    "Z = np.random.uniform(-1,1,(k*k,100))\n",
    "Z = Z.astype(\"float32\")\n",
    "gX = dcgan.sample(None, Z)\n",
    "fig, axes = plt.subplots(k, k, figsize=(20,20))\n",
    "for row, col in itertools.product(range(k), range(k)):\n",
    "    gx = gX[row*k+col]\n",
    "    axes[row,col].get_yaxis().set_visible(False)\n",
    "    axes[row,col].get_xaxis().set_visible(False)\n",
    "    axes[row,col].imshow(rescale((gx.transpose(1,2,0)), invert=True).astype('uint8'))\n",
    "    fig.subplots_adjust(hspace=0, wspace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "k = 10\n",
    "fill1 = np.linspace(-1, 1, k)\n",
    "fill2 = np.linspace(-1, 1, k)\n",
    "fill = np.array(list(itertools.product(fill1,fill2)))\n",
    "Z = np.zeros((k*k, 100))\n",
    "#Z = np.matlib.repmat(np.random.uniform(-1,1,100), k*k, 1)\n",
    "Z[:,:2] = fill\n",
    "Z = Z.astype(\"float32\")\n",
    "gX = dcgan.sample(None, Z)\n",
    "fig, axes = plt.subplots(k, k, figsize=(20,20))\n",
    "for row, col in itertools.product(range(k), range(k)):\n",
    "    gx = gX[row*k+col]\n",
    "    axes[row,col].get_yaxis().set_visible(False)\n",
    "    axes[row,col].get_xaxis().set_visible(False)\n",
    "    axes[row,col].imshow(rescale((gx.transpose(1,2,0)), invert=True).astype('uint8'))\n",
    "    fig.subplots_adjust(hspace=0, wspace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:theano]",
   "language": "python",
   "name": "conda-env-theano-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
